---
title: "Ch 15 from Modern Data Science with R"
subtitle: "Database querying using SQL"
output:
  pdf_document:
    fig_height: 3
    fig_width: 4.5
  html_document: default
  word_document: default
editor_options: 
  chunk_output_type: console
---

```{r, setup, include = FALSE}
# Initial packages required (we'll be adding more)
library(tidyverse)
library(mdsr)      # package associated with our MDSR book
library(DBI)

db <- dbConnect_scidb("airlines")
```


### Section 15.5: Extended example: FiveThirtyEight flights

At [FiveThirtyEight](https://abcnews.go.com/538), Nate Silver wrote [an article about airline delays](https://fivethirtyeight.com/features/fastest-airlines-fastest-airports/) using the same Bureau of Transportation Statistics data that we have in our database. We can use this article as an exercise in querying our airlines database.

The article makes a number of claims, including:

- In 2014, the 6 million domestic flights the U.S. government tracked required an extra 80 million minutes to reach their destinations.  (This is a net number. It consists of about 115 million minutes of delays minus 35 million minutes saved from early arrivals.)

- The majority of flights (54%) arrived ahead of schedule in 2014. 

We can begin by computing the total number of flights, the percentage of those that were on time and ahead of schedule, and the total number of minutes of delays.

```{sql, connection = db, output.var = "mydataframe"}
SELECT
  SUM(1) AS numFlights,
  SUM(IF(arr_delay < 15, 1, 0)) / SUM(1) AS ontimePct,
  SUM(IF(arr_delay < 0, 1, 0)) / SUM(1) AS earlyPct,
  SUM(arr_delay) / 1e6 AS netMinLate,
  SUM(IF(arr_delay > 0, arr_delay, 0)) / 1e6 AS minLate,
  SUM(IF(arr_delay < 0, arr_delay, 0)) / 1e6 AS minEarly
FROM flights AS o
WHERE year = 2014
LIMIT 0, 6;
```

```{r}
mydataframe
```

We see the right number of flights (about 6 million), and the percentage of flights that were early (about 54%) is also about right. The total number of minutes early (about 36 million) is also about right. However, the total number of minutes late is way off (about 78 million vs. 115 million), and as a consequence, so is the net number of minutes late (about 42 million vs. 80 million). 

In this case, you have to read the fine print. A description of the [methodology](https://fivethirtyeight.com/features/how-we-found-the-fastest-flights/) used in this analysis contains some information about the "estimates" of the arrival delay for cancelled flights. The problem is that cancelled flights have an arr_delay value of 0, yet in the real-world experience of travelers, the practical delay is much longer. The FiveThirtyEight data scientists concocted an estimate of the actual delay experienced by travelers due to cancelled flights; they determined a quick-and-dirty answer that cancelled flights are associated with a delay of four or five hours, on average.  However, the calculation varies based on the particular circumstances of each flight.

As a result, reproducing the estimates made by FiveThirtyEight is likely impossible, and certainly beyond the scope of what we can accomplish here. Since we only care about the aggregate number of minutes, we can amend our computation to add, say, 270 minutes of delay time for each cancelled flight to get a ballpark answer.

```{sql, connection = db, output.var = "mydataframe"}
SELECT
  SUM(1) AS numFlights,
  SUM(IF(arr_delay < 15, 1, 0)) / SUM(1) AS ontimePct,
  SUM(IF(arr_delay < 0, 1, 0)) / SUM(1) AS earlyPct,
  SUM(IF(cancelled = 1, 270, arr_delay)) / 1e6 AS netMinLate,
  SUM(
    IF(cancelled = 1, 270, IF(arr_delay > 0, arr_delay, 0))
  ) / 1e6 AS minLate,
  SUM(IF(arr_delay < 0, arr_delay, 0)) / 1e6 AS minEarly
FROM flights AS o
WHERE year = 2014
LIMIT 0, 6;
```

```{r}
mydataframe
```

This correction puts us in the neighborhood of the estimates from the article. One has to read the fine print to properly vet these estimates. The problem is not that the estimates reported by Silver are inaccurate -- on the contrary, they seem plausible and are certainly better than not correcting for cancelled flights at all. However, it is not immediately clear from reading the article (you have to read the separate methodology article) that these estimates -- which account for roughly 25% of the total minutes late reported -- are in fact estimates and not hard data.


Later in the article, Silver presents a figure that breaks down the percentage of flights that were on time, had a delay of 15 to 119 minutes, or were delayed longer than 2 hours (this is the first figure shown).  We will attempt to reproduce this figure. 

```{sql, connection = db, output.var = "res"}
SELECT o.carrier, c.name, 
  SUM(1) AS numFlights,
  SUM(IF(arr_delay > 15 AND arr_delay <= 119, 1, 0)) AS shortDelay,
  SUM(
    IF(arr_delay >= 120 OR cancelled = 1 OR diverted = 1, 1, 0)
  ) AS longDelay
FROM
  flights AS o
LEFT JOIN 
  carriers c ON o.carrier = c.carrier
WHERE year = 2014
GROUP BY carrier
ORDER BY shortDelay DESC
```

After pulling relevant data into R, we begin by pruning less informative labels from the carriers.

```{r}
res <- res |>
  as_tibble() |>
  mutate(
    name = str_remove_all(name, "Air(lines|ways| Lines)"),
    name = str_remove_all(name, "(Inc\\.|Co\\.|Corporation)"),
    name = str_remove_all(name, "\\(.*\\)"),
    name = str_remove_all(name, " *$")
  )
res |>
  pull(name)
```

Next, it is now clear that FiveThirtyEight has considered airline mergers and regional carriers that are not captured in our data. Specifically: "We classify all remaining AirTran flights as Southwest flights," and Envoy Air serves American Airlines. However, there is a bewildering network of alliances among the other regional carriers. Greatly complicating matters, ExpressJet and SkyWest serve multiple national carriers (primarily United, American, and Delta) under different flight numbers. FiveThirtyEight provides a footnote detailing how they have assigned flights carried by these regional carriers, but we have chosen to ignore that here and include ExpressJet and SkyWest as independent carriers. Thus, the data in our figure does not exactly match the figure from FiveThirtyEight.

```{r}
carriers_2014 <- res |>
  mutate(
    groupName = case_when(
      name %in% c("Envoy Air", "American Eagle") ~ "American",
      name == "AirTran" ~ "Southwest", 
      TRUE ~ name
    )
  ) |>
  group_by(groupName) |>
  summarize(
    numFlights = sum(numFlights), 
    wShortDelay = sum(shortDelay), 
    wLongDelay = sum(longDelay)
  ) |>
  mutate(
    wShortDelayPct = wShortDelay / numFlights,
    wLongDelayPct = wLongDelay / numFlights,
    delayed = wShortDelayPct + wLongDelayPct,
    ontime = 1 - delayed
  )
carriers_2014
```

After tidying this data frame using the pivot_longer() function (see Chapter 6), we can draw the figure as a stacked bar chart.

```{r}
# tidy using pivot_longer before plotting
# carriers_2014 is 12x8 (one row per carrier) while carriers_tidy is 24x4
# (one row per carrier and delay type)
carriers_tidy <- carriers_2014 |>
  select(groupName, wShortDelayPct, wLongDelayPct, delayed) |>
  pivot_longer(
    -c(groupName, delayed), 
    names_to = "delay_type", 
    values_to = "pct"
  )
delay_chart <- ggplot(
  data = carriers_tidy, 
  aes(x = reorder(groupName, pct, max), y = pct)
) + 
  geom_col(aes(fill = delay_type)) +
  scale_fill_manual(
    name = NULL, 
    values = c("red", "gold"), 
    labels = c(
      "Flights Delayed 120+ Minutes\ncancelled or Diverted", 
      "Flights Delayed 15-119 Minutes"
    )
  ) + 
  scale_y_continuous(limits = c(0, 1)) + 
  coord_flip() + 
  labs(
    title = "Southwest's Delays Are Short; United's Are Long", 
    subtitle = "As share of scheduled flights, 2014"
  ) + 
  ylab(NULL) + 
  xlab(NULL) + 
  ggthemes::theme_fivethirtyeight() + 
  theme(
    plot.title = element_text(hjust = 1),
    plot.subtitle = element_text(hjust = -0.2)
  )
```

Getting the right text labels in the right places to mimic the display requires additional wrangling.  In fact, by comparing our best attempt to the figure in FiveThirtyEight, it becomes clear that many of the long delays suffered by United and American passengers occur on flights operated by ExpressJet and SkyWest.

```{r}
delay_chart +
  geom_text(
    data = filter(carriers_tidy, delay_type == "wShortDelayPct"), 
    aes(label = paste0(round(pct * 100, 1), "% ")), 
    hjust = "right",
    size = 2
  ) + 
  geom_text(
    data = filter(carriers_tidy, delay_type == "wLongDelayPct"), 
    aes(y = delayed - pct, label = paste0(round(pct * 100, 1), "% ")),
    hjust = "left", 
    nudge_y = 0.01,
    size = 2
  )
```





Replicate 538's plot of slowest and fastest airports, except we use arrival time (which greatly oversimplifies the situation) instead of target time

[Could give this an an exercise for students to convert from book code to something that actually works in R with built-in SQL queries]

```{r}
dests <- dbGetQuery(db, '
SELECT
  dest, 
  SUM(1) AS numFlights,
  AVG(arr_delay) AS avgArrivalDelay
FROM
  flights AS o
WHERE year = 2014
GROUP BY dest
ORDER BY numFlights DESC
LIMIT 0, 30
')

origins <- dbGetQuery(db, '
SELECT
  origin, 
  SUM(1) AS numFlights,
  AVG(arr_delay) AS avgDepartDelay
FROM
  flights AS o
WHERE year = 2014
GROUP BY origin
ORDER BY numFlights DESC
LIMIT 0, 30
')

dests %>%
  left_join(origins, by = c("dest" = "origin")) %>%
  select(dest, avgDepartDelay, avgArrivalDelay) %>%
  arrange(desc(avgDepartDelay))  %>%
  as_tibble()
```

Mimic one more 538 table which ranks carriers by time added vs. typical and time added vs. target.  In this case, we will find average arrival delay after controlling for the routes flown.

```{r}
# first find average arrival delay time by route (combination of dest 
# and origin)
routes <- dbGetQuery(db, '
SELECT 
  origin, dest, 
  SUM(1) AS numFlights,
  AVG(arr_delay) AS avgDelay
FROM
  flights AS o
WHERE year = 2014
GROUP BY origin, dest
')
head(routes)

# Perform the same calculation but add carrier to group by (this is slow!)
routes_carriers <- dbGetQuery(db, '
SELECT 
  origin, dest, 
  o.carrier, c.name, 
  SUM(1) AS numFlights,
  AVG(arr_delay) AS avgDelay
FROM
  flights AS o
LEFT JOIN 
  carriers c ON o.carrier = c.carrier
WHERE year = 2014
GROUP BY origin, dest, o.carrier
')

# merge the two previous data sets to add route averages to individual
# carriers within each route
routes_aug <- routes_carriers %>%
  left_join(routes, by = c("origin" = "origin", "dest" = "dest")) %>%
  as_tibble()
head(routes_aug)

# compute the difference between each carrier's performance and the 
# average performance on each route, and then calculate a weighted 
# average arrival delay for each carrier (weighted by number of flights)
routes_aug %>%
  group_by(carrier) %>%
  # use str_remove_all() to remove parentheses
  summarize(
    carrier_name = str_remove_all(first(name), "\\(.*\\)"), 
    numRoutes = n(), 
    numFlights = sum(numFlights.x), 
    wAvgDelay = sum(
      numFlights.x * (avgDelay.x - avgDelay.y), 
      na.rm = TRUE
    ) / sum(numFlights.x)
  ) %>%
  arrange(wAvgDelay)

```


### Exercises

```{r}
#| Exercise 1 - code from the book
library(RMySQL)
con <- dbConnect(
  MySQL(), host = "scidb.smith.edu",
  user = "waiuser", password = "smith_waiDB", 
  dbname = "wai"
)
Measurements <- tbl(con, "Measurements")
collect(Measurements)

#| this code also works and is much faster
library(RMariaDB)
con <- dbConnect(
  MariaDB(), host = "scidb.smith.edu",
  user = "waiuser", password = "smith_waiDB", 
  dbname = "wai"
)
Measurements <- tbl(con, "Measurements")
collect(Measurements)


#| Supplementary exercise 1 - imdb database.  21 tables can be seen using
#| SHOW TABLES.  

#| Hard to tell if there's anything interesting here (rating, budget, etc.),
#| but this database is used in Ch 20: Networks extended example
db2 <- dbConnect_scidb("imdb")
movie_info <- tbl(db2, "movie_info")
collect(movie_info)  # too big
person_info <- tbl(db2, "person_info")
collect(person_info)  # says cannot allocate vector of size 6.2 Mb??
movie_info_idx <- tbl(db2, "movie_info_idx")
collect(movie_info)  # too big
```

```{sql, connection = db2}
SHOW TABLES;
```

